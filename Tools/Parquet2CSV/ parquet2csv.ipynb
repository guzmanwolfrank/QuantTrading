{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "853feeee",
   "metadata": {},
   "source": [
    "# Parquet2Csv \n",
    "\n",
    "Wolfrank Guzman \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf73baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 currency pair folders.\n",
      "\n",
      "Processing...\n",
      "\n",
      "→ AUD_CHF\n",
      "   Loaded: AUD_CHF_M1_2014_2025_Data.csv (3,895,000 rows)\n",
      "   Saved: AUD_CHF.parquet → 3,895,000 rows (?)\n",
      "\n",
      "→ AUD_JPY\n",
      "   Loaded: AUD_JPY_M1_2014_2025_Data.csv (3,990,000 rows)\n",
      "   Saved: AUD_JPY.parquet → 3,990,000 rows (?)\n",
      "\n",
      "→ AUD_NZD\n",
      "   Loaded: AUD_NZD_M1_2014_2025_Data.csv (3,995,000 rows)\n",
      "   Saved: AUD_NZD.parquet → 3,995,000 rows (?)\n",
      "\n",
      "→ AUD_USD\n",
      "   Loaded: AUD_USD_M1_2014_2025_Data.csv (3,725,000 rows)\n",
      "   Saved: AUD_USD.parquet → 3,725,000 rows (?)\n",
      "\n",
      "→ CAD_CHF\n",
      "   Loaded: CAD_CHF_M1_2014_2025_Data.csv (3,875,000 rows)\n",
      "   Saved: CAD_CHF.parquet → 3,875,000 rows (?)\n",
      "\n",
      "→ CHF_JPY\n",
      "   Loaded: CHF_JPY_M1_2014_2025_Data.csv (4,005,000 rows)\n",
      "   Saved: CHF_JPY.parquet → 4,005,000 rows (?)\n",
      "\n",
      "→ EUR_AUD\n",
      "   Loaded: EUR_AUD_M1_2014_2025_Data.csv (3,935,000 rows)\n",
      "   Saved: EUR_AUD.parquet → 3,935,000 rows (?)\n",
      "\n",
      "→ EUR_CHF\n",
      "   Loaded: EUR_CHF_M1_2014_2025_Data.csv (3,765,000 rows)\n",
      "   Saved: EUR_CHF.parquet → 3,765,000 rows (?)\n",
      "\n",
      "→ EUR_GBP\n",
      "   Loaded: EUR_GBP_M1_2014_2025_Data.csv (3,860,000 rows)\n",
      "   Saved: EUR_GBP.parquet → 3,860,000 rows (?)\n",
      "\n",
      "→ EUR_JPY\n",
      "   Loaded: EUR_JPY_M1_2014_2025_Data.csv (3,935,000 rows)\n",
      "   Saved: EUR_JPY.parquet → 3,935,000 rows (?)\n",
      "\n",
      "→ EUR_USD\n",
      "   Loaded: EUR_USD_M1_2014_2025_Data.csv (3,890,000 rows)\n",
      "   Saved: EUR_USD.parquet → 3,890,000 rows (?)\n",
      "\n",
      "→ GBP_CHF\n",
      "   Loaded: GBP_CHF_M1_2014_2025_Data.csv (3,995,000 rows)\n",
      "   Saved: GBP_CHF.parquet → 3,995,000 rows (?)\n",
      "\n",
      "→ GBP_USD\n",
      "   Loaded: GBP_USD_M1_2014_2025_Data.csv (3,850,000 rows)\n",
      "   Saved: GBP_USD.parquet → 3,850,000 rows (?)\n",
      "\n",
      "→ NZD_CHF\n",
      "   Loaded: NZD_CHF_M1_2014_2025_Data.csv (3,920,000 rows)\n",
      "   Saved: NZD_CHF.parquet → 3,920,000 rows (?)\n",
      "\n",
      "→ NZD_JPY\n",
      "   Loaded: NZD_JPY_M1_2014_2025_Data.csv (4,015,000 rows)\n",
      "   Saved: NZD_JPY.parquet → 4,015,000 rows (?)\n",
      "\n",
      "→ NZD_USD\n",
      "   Loaded: NZD_USD_M1_2014_2025_Data.csv (3,860,000 rows)\n",
      "   Saved: NZD_USD.parquet → 3,860,000 rows (?)\n",
      "\n",
      "→ USD_CAD\n",
      "   Loaded: USD_CAD_M1_2014_2025_Data.csv (3,900,000 rows)\n",
      "   Saved: USD_CAD.parquet → 3,900,000 rows (?)\n",
      "\n",
      "→ USD_CHF\n",
      "   Loaded: USD_CHF_M1_2014_2025_Data.csv (3,595,000 rows)\n",
      "   Saved: USD_CHF.parquet → 3,595,000 rows (?)\n",
      "\n",
      "→ USD_JPY\n",
      "   Loaded: USD_JPY_M1_2014_2025_Data.csv (3,930,000 rows)\n",
      "   Saved: USD_JPY.parquet → 3,930,000 rows (?)\n",
      "\n",
      "→ USD_THB\n",
      "   Loaded: USD_THB_M1_2014_2025_Data.csv (2,335,000 rows)\n",
      "   Saved: USD_THB.parquet → 2,335,000 rows (?)\n",
      "\n",
      "All done! Each currency pair folder now has its merged .parquet file.\n"
     ]
    }
   ],
   "source": [
    "#version 2\n",
    "\n",
    "# convert_1min_csv_to_parquet_in_place.py\n",
    "# Saves one merged .parquet file per currency pair folder\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "ROOT_FOLDER = r\"C:\\Users\\Wolfrank\\Desktop\\AlgoHaus\\OandaHistoricalData\\1MinCharts\"\n",
    "\n",
    "# ============================\n",
    "# MAIN\n",
    "# ============================\n",
    "root = Path(ROOT_FOLDER)\n",
    "\n",
    "# Find all subfolders that look like currency pairs (XXX_YYY format)\n",
    "pair_folders = [f for f in root.iterdir() if f.is_dir() and \"_\" in f.name and len(f.name) == 7]\n",
    "\n",
    "print(f\"Found {len(pair_folders)} currency pair folders.\\n\")\n",
    "print(\"Processing...\\n\")\n",
    "\n",
    "for folder in pair_folders:\n",
    "    pair_name = folder.name  # e.g., \"EUR_USD\"\n",
    "    print(f\"→ {pair_name}\")\n",
    "\n",
    "    # Find all CSV files recursively inside this folder\n",
    "    csv_files = list(folder.rglob(\"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"   No CSV files found in {pair_name}/\\n\")\n",
    "        continue\n",
    "\n",
    "    dataframes = []\n",
    "    for csv in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(csv, parse_dates=True, low_memory=False)\n",
    "            # Standardize column names\n",
    "            df.columns = df.columns.str.strip().str.lower()\n",
    "            df.rename(columns={\n",
    "                \"datetime\": \"time\",\n",
    "                \"date\": \"time\",\n",
    "                \"timestamp\": \"time\"\n",
    "            }, inplace=True)\n",
    "            dataframes.append(df)\n",
    "            print(f\"   Loaded: {csv.name} ({len(df):,} rows)\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Failed to read {csv.name}: {e}\")\n",
    "\n",
    "    if not dataframes:\n",
    "        print(f\"   No valid data loaded for {pair_name}\\n\")\n",
    "        continue\n",
    "\n",
    "    # Merge all CSVs\n",
    "    combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Deduplicate and sort by time\n",
    "    if \"time\" in combined.columns:\n",
    "        combined = combined.drop_duplicates(subset=\"time\", keep=\"first\")\n",
    "        combined = combined.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    # Save Parquet in the same folder\n",
    "    parquet_path = folder / f\"{pair_name}.parquet\"\n",
    "    combined.to_parquet(parquet_path, compression=\"snappy\", index=False)\n",
    "\n",
    "    rows = len(combined)\n",
    "    period = \"?\"\n",
    "    if \"time\" in combined.columns and rows > 0:\n",
    "        try:\n",
    "            start = combined[\"time\"].iloc[0].strftime(\"%Y-%m-%d\")\n",
    "            end = combined[\"time\"].iloc[-1].strftime(\"%Y-%m-%d\")\n",
    "            period = f\"{start} → {end}\"\n",
    "        except:\n",
    "            period = \"?\"\n",
    "\n",
    "    print(f\"   Saved: {parquet_path.name} → {rows:,} rows ({period})\\n\")\n",
    "\n",
    "print(\"All done! Each currency pair folder now has its merged .parquet file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
